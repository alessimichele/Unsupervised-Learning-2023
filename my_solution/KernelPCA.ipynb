{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRBFKernelPCA:\n",
    "    \"\"\"\n",
    "    A small class to perform gaussian kernl PCA\n",
    "    ------------\n",
    "    Attributes:\n",
    "    n_components: int, default is None\n",
    "        number of principal components we want to project on\n",
    "    gamma: float\n",
    "        kernel coefficient (gaussian)\n",
    "    top_k_eigvals_: None\n",
    "        projection matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None, gamma = 1.0):\n",
    "        \"\"\"\n",
    "        Constructor for MyRBFKernelPCA.\n",
    "        ----------\n",
    "        Parameters:\n",
    "        n_components : int (optional)\n",
    "            The number of principal components we want to project on (default is None, meaning to project on all components).\n",
    "        gamma: float\n",
    "            kernel coefficient (gaussian)\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit the kernel PCA model.\n",
    "        ----------\n",
    "        Parameters:\n",
    "        X : numpy array\n",
    "            The data to fit the PCA model and transform, required in the form: (n x p) where n = number of observations and p = number of features\n",
    "        ----------\n",
    "        Returns:\n",
    "        projected_data : numpy array\n",
    "            The projected data.\n",
    "        \"\"\"\n",
    "        # compute the squared Euclidean distances\n",
    "        D = np.sum(X**2, axis=1).reshape(-1, 1) + np.sum(X**2, axis=1) - 2*np.dot(X, X.T)\n",
    "        \n",
    "        # compute the RBF kernel matrix\n",
    "        K = np.exp(-self.gamma*D)\n",
    "\n",
    "        # double center the kernel matrix\n",
    "        n = K.shape[0]\n",
    "        one_n = np.ones((n, n)) / n\n",
    "        K_centered = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)\n",
    "        \n",
    "\n",
    "        eig_vals, eig_vecs = np.linalg.eig(K_centered)\n",
    "        eig_vals = np.where(eig_vals<0,0, eig_vals)\n",
    "        sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "        sorted_eigvecs = eig_vecs[:,sorted_indices]\n",
    "        sorted_eigvals = eig_vals[sorted_indices]\n",
    "\n",
    "        # select the first k eigenvector(s) and project\n",
    "        top_k_eigvecs = sorted_eigvecs[:,:self.n_components]\n",
    "        top_k_eigvals = sorted_eigvals[:self.n_components]\n",
    "\n",
    "        # projected_data = np.dot(K_centered, self.top_k_eigvecs) sbagliato, capire perche \n",
    "\n",
    "        return np.dot(top_k_eigvecs, np.sqrt(np.diag(top_k_eigvals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol(x,y, gamma, d):\n",
    "    \"\"\"\n",
    "    Polynomial kernel function between two feature vectors. \n",
    "    ----------\n",
    "    Parameters:\n",
    "        x, y (`numpy.ndarray`): feature vectors to compute the kernel between.\n",
    "        gamma (float): Scaling factor.\n",
    "        d (int): Degree of the polynomial. \n",
    "    Returns:\n",
    "        float: Kernel function output.\n",
    "    \"\"\"\n",
    "    return (gamma*np.dot(x,y) + 1)**d\n",
    "\n",
    "\n",
    "class MyPolyKernelPCA:\n",
    "    \"\"\"\n",
    "    Kernel PCA using polynomial kernel function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None, gamma = 1.0, d = 2):\n",
    "        \"\"\"\n",
    "        Constructor method that initializes class variables. \n",
    "        ----------\n",
    "        Parameters:\n",
    "        n_components: int\n",
    "            Number of principal components to project on (default is None, meaning to project on all components).\n",
    "        gamma: float, default = 1.0 \n",
    "            Scaling factor.\n",
    "        d: int, default = 2\n",
    "            Degree of the polynomial. \n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.gamma = gamma\n",
    "        self.d = d\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix between all observations in X and use it to fit the kernel PCA model onto data X and return the projected data. \n",
    "        ----------\n",
    "        Parameters:\n",
    "        X: numpy.ndarray\n",
    "            Data to fit and transform. Required in the form: (n x p) where n = number of observations and p = number of features.\n",
    "        Returns:\n",
    "            numpy.ndarray: The projected data. \n",
    "        \"\"\"\n",
    "        # compute the squared Euclidean distances\n",
    "        K = np.zeros([X.shape[0], X.shape[0]])\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                K[i,j] = pol(X[i], X[j], gamma=self.gamma, d = self.d)\n",
    "\n",
    "        # double center the kernel matrix\n",
    "        n = K.shape[0]\n",
    "        one_n = np.ones((n, n)) / n\n",
    "        K_centered = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)\n",
    "\n",
    "        # compute the eigenvalues and eigenvectors of the kernel matrix\n",
    "        eig_vals, eig_vecs = np.linalg.eig(K_centered)\n",
    "        eig_vals = np.where(eig_vals<0,0, eig_vals)\n",
    "        sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "        sorted_eigvecs = eig_vecs[:,sorted_indices]\n",
    "        sorted_eigvals = eig_vals[sorted_indices]\n",
    "\n",
    "        # select the first k eigenvectors and eigenvalues and project\n",
    "        top_k_eigvecs = sorted_eigvecs[:,:self.n_components]\n",
    "        top_k_eigvals = sorted_eigvals[:self.n_components]\n",
    "    \n",
    "        return np.dot(top_k_eigvecs, np.sqrt(np.diag(top_k_eigvals)))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
